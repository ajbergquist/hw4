{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mountain Car: Explicit Policy #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy ##\n",
    "In order for the car to reach the top of the mountain, it must build up its energy. This can be achieved by always applying force in the direction of the car's movement. If the car is moving right, that is, the velocity is positive, we push the car to the right, and if the car is moving left, i.e. velocity is negative, we push the car to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions\n",
    "PUSH_LEFT = 0\n",
    "PUSH_RIGHT = 2\n",
    "NO_PUSH = 1\n",
    "\n",
    "# Explicit Policy: Always accelerate in the direction that the cart is moving.\n",
    "def policy(state):\n",
    "    _, velocity = state\n",
    "    \n",
    "    # Choose next action\n",
    "    if velocity >= 0.0:\n",
    "        action = PUSH_RIGHT\n",
    "    else:\n",
    "        action = PUSH_LEFT\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ##\n",
    "Run a number of episodes to demonstrate the effectiveness of the explicit policy. Print out the result of each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 : Succeeded in 120 steps. Position = 0.5110058309018083\n",
      "Episode 1 : Succeeded in 115 steps. Position = 0.5368577983788596\n",
      "Episode 2 : Succeeded in 120 steps. Position = 0.5139194252704854\n",
      "Episode 3 : Succeeded in 113 steps. Position = 0.5368577983788596\n",
      "Episode 4 : Succeeded in 114 steps. Position = 0.5368577983788596\n",
      "Episode 5 : Succeeded in 121 steps. Position = 0.5152104230269557\n",
      "Episode 6 : Succeeded in 113 steps. Position = 0.5368577983788596\n",
      "Episode 7 : Succeeded in 112 steps. Position = 0.5368577983788596\n",
      "Episode 8 : Succeeded in 120 steps. Position = 0.5108730967512972\n",
      "Episode 9 : Succeeded in 122 steps. Position = 0.5284171264106424\n",
      "Episode 10 : Succeeded in 113 steps. Position = 0.5368577983788596\n",
      "Episode 11 : Succeeded in 120 steps. Position = 0.5194680346739984\n",
      "Episode 12 : Succeeded in 121 steps. Position = 0.5058795804143007\n",
      "Episode 13 : Succeeded in 121 steps. Position = 0.5267844450046685\n",
      "Episode 14 : Succeeded in 120 steps. Position = 0.5368577983788596\n",
      "Episode 15 : Succeeded in 113 steps. Position = 0.5368577983788596\n",
      "Episode 16 : Succeeded in 123 steps. Position = 0.538543288904316\n",
      "Episode 17 : Succeeded in 122 steps. Position = 0.5262409458884827\n",
      "Episode 18 : Succeeded in 112 steps. Position = 0.5368577983788596\n",
      "Episode 19 : Succeeded in 123 steps. Position = 0.534341517585891\n"
     ]
    }
   ],
   "source": [
    "NUM_EPISODES = 20\n",
    "MAX_STEPS = 200\n",
    "\n",
    "for i in np.arange(NUM_EPISODES):\n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    for j in np.arange(MAX_STEPS):\n",
    "        # Determine the next action to take from the policy\n",
    "        action = policy(state)\n",
    "        \n",
    "        # Take next step\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            pos = state[0]\n",
    "            if pos >= 0.5:\n",
    "                print(\"Episode\", i, \": Succeeded in\", j, \"steps. Position =\", pos)\n",
    "            else:\n",
    "                print(\"Episode\", i, \": Failed. Position =\", pos)\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
